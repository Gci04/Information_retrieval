{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language and Topic models\n",
    "\n",
    "A common suggestion to users for coming up with good queries is to think of words that would likely appear in a relevant document, and to use those words as the query. The language modeling approach to IR directly models this idea: a document is a good match to a query if the document model is likely to generate the query, which will in turn happen if the document contains the query words often. \n",
    "\n",
    "Today we will score documents with respect to user query using language models and also get some experience with topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all required modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import os, tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "In this class we will use the dataset we already used once - [this topic-modeling dataset](https://code.google.com/archive/p/topic-modeling-tool/downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir = './data'):\n",
    "    all_data = {}\n",
    "    try :\n",
    "        assert os.path.isdir(data_dir), 'file not found'\n",
    "        print(f'Reading data from : {data_dir}')\n",
    "        (_, _, filenames)  = next(os.walk('./data'))\n",
    "        for doc in filenames:\n",
    "            try:\n",
    "                with open(os.path.join(data_dir,doc),'r') as file:\n",
    "                    text = file.readlines()\n",
    "                    topic = doc.split('.')[0]\n",
    "                    for i , line in enumerate(text,1):\n",
    "                        all_data[f'{topic}_{i}'] = line\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "    except :\n",
    "        print(\"Downloading data ...\")\n",
    "        os.mkdir(data_dir)\n",
    "        links = {\"fuel\":\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/topic-modeling-tool/testdata_news_fuel_845docs.txt\",\n",
    "                \"economy\":\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/topic-modeling-tool/testdata_news_economy_2073docs.txt\",\n",
    "                \"music\": \"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/topic-modeling-tool/testdata_news_music_2084docs.txt\",\n",
    "                \"brain_injury\":\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/topic-modeling-tool/testdata_braininjury_10000docs.txt\"}\n",
    "        \n",
    "        for topic, link in tqdm.tqdm_notebook(links.items()):\n",
    "            f = urlopen(link)\n",
    "            myfile = f.readlines()\n",
    "            file = open('./data/'+topic+'.txt','w+')\n",
    "            for i , doc in enumerate(myfile,1):\n",
    "                decoded_doc = doc.decode('utf-8').strip()\n",
    "                all_data[f'{topic}_{i}'] = decoded_doc\n",
    "                file.write(decoded_doc+\"\\n\") # save the file to local dir\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from : ./data\n",
      "# of documents 15002\n"
     ]
    }
   ],
   "source": [
    "all_data = read_data()\n",
    "print(\"# of documents\", len(all_data))\n",
    "assert len(all_data) == 15002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ranking Using Language Models\n",
    "Our goal is to rank documents by *P(d|q)*, where the probability of a document is interpreted as the likelihood that it is relevant to the query. \n",
    "\n",
    "Using Bayes rule: *P(d|q) = P(q|d)P(d)/P(q)*\n",
    "\n",
    "*P(q)* is the same for all documents, and so can be ignored. The prior probability of a document *P(d)* is often treated as uniform across all *d* and so it can also be ignored. What does it mean? \n",
    "\n",
    "It means that comparing *P(q|d)* between different documents we can compare how relevant are they to the query. How can we estimate *P(q|d)*?\n",
    "\n",
    "*P(q|d)* can be estimated as:\n",
    "![](https://i.imgur.com/BEIMAC1.png)\n",
    "\n",
    "where M<sub>d</sub> is the language model of document *d*, tf<sub>t,d</sub> is the term frequency of term *t* in document *d*, and L<sub>d</sub> is the number of tokens in document *d*. That is, we just count up how often each word occurred, and divide by the total number of words in the document *d*. The first thing we need to do is to build a term-document matrix for tour dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build term-document matrix for the dataset\n",
    "vectorizer = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "tdm = vectorizer.fit_transform(list(all_data.values())).toarray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "Now, you need to implement the abovementioned logic in the `lm_rank_documents` function below. Do you see any potential problems?\n",
    "\n",
    "Yes, data sparsity - we don't expect to meet each term in each doc, so, in most cases, we will get zero scores, which is not what we really want.\n",
    "\n",
    "The solution is smooting.\n",
    "\n",
    "One option is *additive smoothing* - adding a small number (0 to 1) to the observed counts and renormalizing to give a probability distribution.\n",
    "\n",
    "Another option is called Jelinek-Mercer smoothing - a simple idea that works well in practice is to use a mixture between a document-specific distribution and distribution estimated from the entire collection:\n",
    "\n",
    "![](https://i.imgur.com/8Qv41Wp.png)\n",
    "\n",
    "where 0 < Î» < 1 and M<sub>c</sub> is a language model built from the entire document collection.\n",
    "\n",
    "Refer to *Chapter 12* for the detailed explanation.\n",
    "\n",
    "\n",
    "You are going to apply both in your `lm_rank_documents` function. This function takes as an input tdm matrix, and ranks all documents \"building\" a language model for each document, returning relative probabilities of query being generated by a document as a document's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_rank_documents(query, tdm, terms_list, doc_names,smoothing='additive', param=0.001):\n",
    "    result = []\n",
    "    if smoothing == 'additive':\n",
    "        #additive smoothing\n",
    "        alpha = param\n",
    "        tdm += alpha\n",
    "        tdm /= tdm.sum(axis=1).reshape(-1,1) #Renormalizing\n",
    "        \n",
    "        # Sort & return results\n",
    "        return sorted(result, key= lambda x : x[1], reverse=True) #Sort re\n",
    "    \n",
    "    else:\n",
    "        # Jelinek-Mercer smoothing\n",
    "        full_ptd = {}\n",
    "        doc_len = tdm.sum(axis=0)\n",
    "\n",
    "        for w, c in tqdm.tqdm_notebook(zip(np.array(terms_list),tdm)):\n",
    "            #Probability of term in each document -- Takes forever to finish\n",
    "            full_ptd.update({ w : {doc_names[i] : c[i]/doc_len[i] for i in np.nonzero(c)[0]}})\n",
    "            \n",
    "        # get probability of term in full context\n",
    "        full_ptc = dict(zip(terms_list,tdm.sum(axis=1)/tdm.sum())) \n",
    "\n",
    "        lambd = param\n",
    "        result = []\n",
    "        for doc in tqdm.tqdm_notebook(doc_names):\n",
    "            score = 1.0\n",
    "            # score*=p(t|d)\n",
    "            for qw in query:\n",
    "                ptd = full_ptd.get(qw,{}).get(doc,1) #P(t|Md)\n",
    "                ptc = full_ptc.get(qw,1) #P(t|Mc)\n",
    "                pd = lambd * ptd + (1-lambd) * ptc \n",
    "                score *= pd\n",
    "            \n",
    "            # Add document score to result\n",
    "            result.append((doc, score))\n",
    "            \n",
    "        # Sort & return results\n",
    "        return  sorted(result, key= lambda x : x[1], reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Check if this type of ranking gives meaningful results. For each query output document category, doc_id, score, and the beginning of the document, as it is shown below. Analyze if categories and contents match the queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color='red'>Implementation Not Finished !!!</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query: \u001b[95mpiano concert\u001b[0m\n",
      "prepared query: Counter({'piano': 1, 'concert': 1})\n",
      "\n",
      "search results:\n",
      "\u001b[1mmusic\u001b[0m 13330 0.012384164490679759\n",
      "atlanta prominent midtown intersection one step closer becoming major cultural landmark the atlanta ...\n",
      "\u001b[1meconomy\u001b[0m 11335 0.012384164490679759\n",
      "atlanta prominent midtown intersection one step closer becoming major cultural landmark the atlanta ...\n",
      "\u001b[1mmusic\u001b[0m 12926 0.011382499792705511\n",
      "felt like was going church marry guy never met said the jazz violinist regina carter the metaphorica...\n",
      "\u001b[1mmusic\u001b[0m 14390 0.010661589922122\n",
      "hailed los angeles brightest flower its flashiest ship sail its keenest architectural triumph perhap...\n",
      "\u001b[1mmusic\u001b[0m 13818 0.010549141787975117\n",
      "everything was finished sept the super bowl logo would reflection new orleans featuring streetcar an...\n",
      "\n",
      "\n",
      "user query: \u001b[95msymptoms of head trauma\u001b[0m\n",
      "prepared query: Counter({'symptoms': 1, 'head': 1, 'trauma': 1})\n",
      "\n",
      "search results:\n",
      "\u001b[1mbrain_injury\u001b[0m 7319 0.06022877378376099\n",
      "the direct economic burden blunt and penetrating trauma managed care population background although ...\n",
      "\u001b[1mbrain_injury\u001b[0m 6987 0.05854539395767944\n",
      "history reported head trauma sample women substance abuse treatment objectives determine the prevale...\n",
      "\u001b[1mbrain_injury\u001b[0m 5257 0.05760140208255336\n",
      "violent head trauma china report cases background the occurrence violent trauma has recently increas...\n",
      "\u001b[1mbrain_injury\u001b[0m 1536 0.055365767080148634\n",
      "mild head trauma and chronic headaches returning soldiers objective determine the incidence and type...\n",
      "\u001b[1mbrain_injury\u001b[0m 8874 0.05379997937839304\n",
      "maxillofacial trauma major trauma patients background trauma has been identified major public health...\n",
      "\n",
      "\n",
      "user query: \u001b[95mwall street journal\u001b[0m\n",
      "prepared query: Counter({'wall': 1, 'street': 1, 'journal': 1})\n",
      "\n",
      "search results:\n",
      "\u001b[1meconomy\u001b[0m 11294 0.027288833622119528\n",
      "these business stories for release tuesday january are moving today clients the new york times news ...\n",
      "\u001b[1meconomy\u001b[0m 11295 0.027288833622119528\n",
      "these business stories for release tuesday january are moving today clients the new york times news ...\n",
      "\u001b[1mmusic\u001b[0m 14641 0.026716049665405375\n",
      "these feature stories are moving today clients the new york times news service stories are for relea...\n",
      "\u001b[1mmusic\u001b[0m 14640 0.026716049665405375\n",
      "these feature stories are moving today clients the new york times news service stories are for relea...\n",
      "\u001b[1meconomy\u001b[0m 11297 0.025763725974814314\n",
      "these feature stories are moving today clients the new york times news service stories are for relea...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_query(raw_query):\n",
    "    # TODO: process user query and print search results including document category, id, score, and some part of it\n",
    "    query = query.split(\" \")\n",
    "    #lm_rank = lm_rank_documents()\n",
    "    \n",
    "\n",
    "user_queries = [\"piano concert\", \"symptoms of head trauma\", \"wall street journal\"]\n",
    "for q in user_queries:\n",
    "    process_query(q)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Topic modeling\n",
    "\n",
    "Now let's use *Latent Dirichlet Allocation* to identify topics in this collection and check if they match the original topics (fuel, economy, etc.). Go through the tutorial [here](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0) and apply the ideas there to our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Print function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for LDA Model fit\n",
    "number_topics = 4\n",
    "vectorizer = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "data = vectorizer.fit_transform(list(all_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=4, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "the and that for said with new its are have from company has was but percent more year will york they not enron their than which had about last companies this times been would million were market one when some business his who economy feb also stock other out years\n",
      "\n",
      "Topic #1:\n",
      "the and that for with was his but from you she are said they her who have has this one not new about when all had their there more like can were what out people which will been music just says time two than into after first some its would\n",
      "\n",
      "Topic #2:\n",
      "the and with patients was were injury for brain this after that traumatic from study are tbi results injuries trauma head treatment had between severe not outcome clinical patient these group methods cases years all may children case who than associated have during age fractures using more data following one\n",
      "\n",
      "Topic #3:\n",
      "the and that for with said are new will has from news but have his atlanta was they bush this not who service their more year about york president journal would washington constitution all enron its undated one been times than which government some state com moved last other were\n"
     ]
    }
   ],
   "source": [
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, vectorizer, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
